{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인기제품 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "use_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "\n",
    "# 사용자 정보\n",
    "users = pd.read_csv('./u.user', sep = '|', names = use_cols, encoding = 'latin-1')\n",
    "users = users.set_index('user_id')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'unknown',\n",
    "            'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary',\n",
    "             'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "            'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "# 영화 정보와 영화 평점 정보\n",
    "movies = pd.read_csv('./u.item', sep='|', names=item_cols, encoding='latin-1')\n",
    "movies = movies.set_index('movie_id')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 영화 평점 정보\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "ratings = pd.read_csv('./u.data', sep='\\t', names = rating_cols, encoding = 'latin-1')\n",
    "ratings = ratings.set_index('user_id')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-Seller\n",
    "def recom_movie1(n_items):\n",
    "    movie_sort = movie_mean.sort_values(ascending=False)[:n_items]\n",
    "    recom_movies = movies.iloc[movie_sort.index, :]\n",
    "    recommendations = recom_movies['title']\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# def recom_movie2(n_items):\n",
    "#     return movies.iloc[movie_mean.sort_values[ascending=False][:n_items].index]['title']\n",
    "\n",
    "movie_mean = ratings.groupby(['movie_id'])['rating'].mean()\n",
    "recom_movie1(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "rmse = []\n",
    "for user in set(ratings.index):\n",
    "    y_true = ratings.loc[user]['rating']\n",
    "    y_pred = movie_mean[ratings.loc[user]['movie_id']]\n",
    "    acc = RMSE(y_true, y_pred)\n",
    "    rmse.append(acc)\n",
    "    \n",
    "print(np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 집단별 추천\n",
    "+ users, movies, ratings\n",
    "+ merged_matrix, rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 필요 데이터를 로드한다.\n",
    "use_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./u.user', sep = '|', names = use_cols, encoding = 'latin-1')\n",
    "item_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'unknown',\n",
    "            'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary',\n",
    "             'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "            'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('./u.item', sep='|', names=item_cols, encoding='latin-1')\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./u.data', sep='\\t', names = rating_cols, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 열은 제거하고, 사용할 열만 가져옴\n",
    "ratings = ratings.drop('timestamp', axis = 1) \n",
    "movies = movies[['movie_id', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = ratings.copy()\n",
    "y = ratings['user_id']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지표 정의\n",
    "import numpy as np\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "# y_pred는 x_train으로 얻어진 matrix에서 계산한 rating이고,\n",
    "# y_true는 실제 데이터에서 유저가 특정 영화를 평가한 rating이다.\n",
    "def score(model):\n",
    "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
    "    y_pred = np.array([model(user, movie) for (user, movie) in id_pairs])\n",
    "    y_true = np.array(x_test['rating'])\n",
    "    \n",
    "    return RMSE(y_true, y_pred)\n",
    "\n",
    "# 사용자/영화로 피봇 테이블을 생성\n",
    "rating_matrix = x_train.pivot(index = 'user_id', columns = 'movie_id', values = 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_seller(user_id, movie_id):\n",
    "    try:\n",
    "        rating = train_mean[movie_id]\n",
    "    except:\n",
    "        rating = 3.0\n",
    "    return rating\n",
    "\n",
    "train_mean = x_train.groupby(['movie_id'])['rating'].mean()\n",
    "score(best_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_matrix = pd.merge(x_train, users)\n",
    "users = users.set_index('user_id')\n",
    "\n",
    "g_mean = merged_matrix[['movie_id', 'sex', 'rating']].groupby(['movie_id', 'sex'])['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender 기준 추천\n",
    "def cf_gender(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        gender = users.loc[user_id]['sex']\n",
    "        if gender in g_mean[movie_id]:\n",
    "            gender_rating = g_mean[movie_id][gender]\n",
    "        else:\n",
    "            gender_rating = 3.0\n",
    "            \n",
    "    else:\n",
    "        gender_rating = 3.0\n",
    "        \n",
    "    return gender_rating\n",
    "\n",
    "score(cf_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제 2-1\n",
    "+ 직업별 영화 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_mean = merged_matrix[['movie_id', 'occupation', 'rating']].groupby(['movie_id', 'occupation'])['rating'].mean()\n",
    "\n",
    "def cf_occupation(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        occ = users.loc[user_id, :]['occupation']\n",
    "        if occ in occ_mean[movie_id]:\n",
    "            occ_rating = occ_mean[movie_id][occ]\n",
    "        else:\n",
    "            occ_rating = 3.0\n",
    "    else:\n",
    "        occ_rating = 3.0\n",
    "        \n",
    "    return occ_rating\n",
    "\n",
    "score(cf_occupation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제 2-2\n",
    "+ 성별과 직업을 동시 고려한 영화 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_mean = merged_matrix[['movie_id', 'sex', 'occupation','rating']].groupby(['movie_id', 'sex', 'occupation'])['rating'].mean()\n",
    "\n",
    "def cf_scc(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        sex = users.loc[user_id, :]['sex']\n",
    "        occ = users.loc[user_id, :]['occupation']\n",
    "        if (sex in scc_mean[movie_id]) and (occ in scc_mean[movie_id][sex]):\n",
    "            scc_rating = scc_mean[movie_id][sex][occ]\n",
    "        else:\n",
    "            scc_rating = 3.0\n",
    "    else:\n",
    "        scc_rating = 3.0\n",
    "        \n",
    "    return scc_rating\n",
    "\n",
    "score(cf_scc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index = rating_matrix.index, columns = rating_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF_simple(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        movie_ratings = rating_matrix[movie_id].copy()\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.dropna()\n",
    "        sim_scores = sim_scores.drop(none_rating_idx) # (348, )\n",
    "        mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "        \n",
    "    return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(CF_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, neighbor_size = 0):\n",
    "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
    "    y_pred = np.array([model(user, movie, neighbor_size) for (user, movie) in id_pairs])\n",
    "    y_true = np.array(x_test['rating'])\n",
    "    \n",
    "    return RMSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_knn(user_id, movie_id, neighbor_size = 0):\n",
    "    if movie_id in rating_matrix:\n",
    "        # 해당 유저와 다른 유저와의 유사성\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        # 해당 영화 평점만\n",
    "        movie_ratings = rating_matrix[movie_id].copy()\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.dropna()\n",
    "        sim_scores = sim_scores.drop(none_rating_idx) # (348, )\n",
    "        \n",
    "        if neighbor_size == 0:\n",
    "            mean_rating = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                mean_rating = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "            else:\n",
    "                mean_rating = 3.0\n",
    "        \n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "        \n",
    "    return mean_rating\n",
    "\n",
    "score(cf_knn, neighbor_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = ratings.pivot_table(values = 'rating', index = 'user_id', columns = 'movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index = rating_matrix.index, columns= rating_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_movie(user_id, n_items, neighbor_size = 30):\n",
    "    user_movie = rating_matrix.loc[user_id].copy()\n",
    "    for movie in rating_matrix:\n",
    "        if pd.notnull(user_movie.loc[movie]):\n",
    "            user_movie.loc[movie] = 0\n",
    "        else:\n",
    "            user_movie.loc[movie] = cf_knn(user_id, movie, neighbor_size)\n",
    "    movie_sort = user_movie.sort_values(ascending = False)[:n_items]\n",
    "    recom_movies = movies.loc[movie_sort.index]\n",
    "    recommendations = recom_movies['title']\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recom_movie(user_id = 2, n_items = 5, neighbor_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = ratings.pivot_table(values = 'rating', index = 'user_id', columns = 'movie_id')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index = rating_matrix.index, columns= rating_matrix.index)\n",
    "\n",
    "for neighbor_size in [10, 20, 30, 40, 50, 60]:\n",
    "    print(score(cf_knn, neighbor_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mean = rating_matrix.mean(axis = 1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_knn(user_id, movie_id, neighbor_size = 0):\n",
    "    if movie_id in rating_bias:\n",
    "        # 해당 유저와 다른 유저와의 유사성\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        # 해당 영화 평점만\n",
    "        movie_ratings = rating_bias[movie_id].copy()\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.dropna()\n",
    "        sim_scores = sim_scores.drop(none_rating_idx) # (348, )\n",
    "        \n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                prediction = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "        \n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_binary1 = np.array((rating_matrix > 0).astype(float))\n",
    "rating_binary2 = rating_binary1.T\n",
    "counts = np.dot(rating_binary1, rating_binary2)\n",
    "counts = pd.DataFrame(counts, index = rating_matrix.index, columns = rating_matrix.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF_knn_bias_sig(user_id, movie_id, neighbor_size = 0):\n",
    "    if movie_id in rating_bias:\n",
    "        # 해당 유저와 다른 유저와의 유사성\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        # 해당 영화 평점만\n",
    "        movie_ratings = rating_bias[movie_id].copy()\n",
    "        # 현재 영화에 대해서 평가하지 않은 사용자를 True로 표시\n",
    "        no_rating = movie_ratings.isnull()\n",
    "        # 현재 사용자와 다른 사용자와의 공통 영화 평가 갯수를 가져옴\n",
    "        common_counts = counts[user_id]\n",
    "        # 미리 정해진 공통 평가 영화 숫자보다 작은 경우 True로 표시한다.\n",
    "        low_significant = common_counts < SIG_LEVEL\n",
    "        # 평가하지 않았고, 공통 평가 영화 숫자보다 작은 경우\n",
    "        # 평가하지 않았고, 공통 평가 영화 숫자보다 큰 경우\n",
    "        # 평가했지만, 공통 평가 영화 숫자보다 작은 경우\n",
    "        # 위의 경우를 모두 제외\n",
    "        none_rating_idx = movie_ratings[no_rating | low_significant].index\n",
    "        movie_ratings = movie_ratings.dropna()\n",
    "        sim_scores = sim_scores.drop(none_rating_idx) # (348, )\n",
    "        \n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "        else:\n",
    "            if len(sim_scores) > MIN_RATINGS:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                prediction = np.dot(sim_scores,movie_ratings) /sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "        \n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "        \n",
    "    if prediction < 1:\n",
    "        prediction = 1\n",
    "    elif prediction > 5:\n",
    "        prediction = 5\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_LEVEL=3\n",
    "MIN_RATINGS = 2\n",
    "score(CF_knn_bias_sig, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = ratings.pivot_table(values = 'rating', index = 'user_id', columns = 'movie_id')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "rating_matrix_t = np.transpose(rating_matrix)\n",
    "matrix_dummy = rating_matrix_t.copy().fillna(0)\n",
    "item_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "item_similarity = pd.DataFrame(item_similarity, index = rating_matrix_t.index, columns= rating_matrix_t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CF_IBCF(user_id, movie_id):\n",
    "    if movie_id in item_similarity:\n",
    "        sim_scores = item_similarity[movie_id]\n",
    "        user_rating = rating_matrix_t[user_id]\n",
    "        non_rating_idx = user_rating[user_rating.isnull()].index\n",
    "        sim_scores = sim_scores.drop(non_rating_idx)\n",
    "        mean_rating = np.dot(sim_scores, user_rating) / sim_scores.sum()\n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "    return mean_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors ** 2))\n",
    "    \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i + 1, rmse))\n",
    "            if self.verbose:\n",
    "                if(i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f\" % (i +1, rmse))\n",
    "        return training_process\n",
    "    \n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "            \n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "\n",
    "R_temp = ratings.pivot(index= 'user_id', columns = 'movie_id', values = 'rating').fillna(0)\n",
    "mf = MF(R_temp, K = 30, alpha = 0.001, beta = 0.02, iterations =100, verbose = True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ratings_train 여기서) 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state = 1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = np.array(ratings)\n",
    "        \n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id = in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        \n",
    "        user_id_index = []; index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "            \n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors ** 2))\n",
    "    \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i + 1, rmse))\n",
    "            if self.verbose:\n",
    "                if(i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f\" % (i +1, rmse))\n",
    "        return training_process\n",
    "    \n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def set_test(selft, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0\n",
    "        self.test_set = test_set\n",
    "        \n",
    "        return test_set\n",
    "    \n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "    \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "            \n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "            \n",
    "    def test(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "        training_process = []\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i + 1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if(i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f; Test RMSE = %.4f\" % (i +1, rmse1, rmse2))\n",
    "        return training_process\n",
    "    \n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        \n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:, np.newaxis] + self.b_d[np.newaxis, :] + self.P.dot(self.Q.T)\n",
    "    \n",
    "R_temp = ratings.pivot(index= 'user_id', columns = 'movie_id', values = 'rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K = 30, alpha = 0.001, beta = 0.02, iterations =100, verbose = True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "index = []\n",
    "# 최적의 K 찾기\n",
    "for k in range(50, 261, 10):\n",
    "    print('K = ', K)\n",
    "    R_temp = ratings.pivot(index= 'user_id', columns = 'movie_id', values = 'rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K = K, alpha = 0.001, beta = 0.02, iterations =100, verbose = True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for i in range(len(results)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j + 1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.ylim(0.89, 0.94)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = KNNWithMeans()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [BsaelineOnly, KNNwithMeans, SVD, SVDpp]\n",
    "names = []\n",
    "results = []\n",
    "for option in algorithms:\n",
    "    algo = option()\n",
    "    names.append(option.__name__)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    results.append(accuracy.rmse(predictions))\n",
    "    \n",
    "names = np.array(names); results = np.array(results)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "index = np.argsort(results)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(names[index], results[index])\n",
    "results[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson_baseline', 'user_based':True}\n",
    "algo = KNNwithMeans(k = 30, sim_options = sim_options)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =[]\n",
    "for neighbor_size in (10, 20, 30, 40, 50, 60):\n",
    "    algo = KNNwithMeans(k=neighbor_size,sim_options = {'name': 'pearson_baseline', 'user_based':True})\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    result.append([neighbor_size, accuracy.rmse(predictions)])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'k':[5, 10, 15, 25],\n",
    "             'sim_options':{'name':['pearson_baseline', 'cosine'],\n",
    "                           'user_based':['True, False']}}\n",
    "gs = GridSearchCV(KNNwithMeans, param_grid, measures = ['rmse'], cv= 4)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs':[70, 80, 90],\n",
    "             'lr_all':[0.005, 0.006, 0.007],\n",
    "             'reg_all':[0.05, 0.07, 0.1]}\n",
    "gs = GridSearchCV(KNNwithMeans, param_grid, measures = ['rmse'], cv= 4)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.dataset import Reader\n",
    "\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./u.data', sep='\\t', names = rating_cols, encoding = 'latin-1')\n",
    "reader = Reader(rating_scale =(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 200\n",
    "mu = ratings_train.rating.mean()\n",
    "M = ratings.user_id.max() + 1\n",
    "N = ratings.movie_id.max() + 1\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "user = Input(shape = (1, ))\n",
    "item = Input(shape = (1, ))\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer = l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer = l2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer = l2())(user) \n",
    "item_bias = Embedding(N, 1, embeddings_regularizer = l2())(item) \n",
    "\n",
    "R = layers.dot([P_embedding, Q_embedding], axes = 2, name = 'dot_layer')\n",
    "R = layers.add([R, user_bias, item_bias])\n",
    "R = Flatten()(R)\n",
    "\n",
    "model = Model(inputs = [user, item], outputs = R)\n",
    "model.compile(loss = RMSE, optimizer = SGD(), metrics = [RMSE])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(x = [ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "                  y = ratings_train.rating.values - mu,\n",
    "                  epochs = 60,\n",
    "                  batch_size = 256,\n",
    "                  validation_data = ([ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "                                    ratings_test.rating.values - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result.history['RMSE'], label = 'Train RMSE')\n",
    "plt.plot(result.history['val_RMSE'], label = 'Test RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings_test.user_id.values[0:6]\n",
    "movie_ids = ratings_test.movie_id.values[0:6]\n",
    "predictions = model.predict([user_ids, movie_ids]) + mu\n",
    "print('Actuals: \\n', ratings_test[0:6])\n",
    "print()\n",
    "print('Predictions: \\n', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "user_ids = ratings_test.user_id.values\n",
    "movie_ids = ratings_test.movie_id.values\n",
    "y_pred = model.predict([user_ids, movie_ids]) + mu\n",
    "y_pred = np.ravel(y_pred, order = 'C')\n",
    "y_true = np.array(ratings_test.rating)\n",
    "\n",
    "RMSE2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Input(shape = (1, ))\n",
    "item = Input(shape = (1, ))\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer = l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer = l2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer = l2())(user) \n",
    "item_bias = Embedding(N, 1, embeddings_regularizer = l2())(item) \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "P_embedding = Flatten()(P_embedding)\n",
    "Q_embedding = Flatten()(Q_embedding)\n",
    "user_bias = Flatten()(user_bias)\n",
    "item_bias = Flatten()(item_bias)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Dense(2048)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n",
    "model = Model(inputs = [user, item], outputs = R)\n",
    "model.compile(loss = RMSE, optimizer = SGD(), metrics = [RMSE])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(x = [ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "                  y = ratings_train.rating.values - mu,\n",
    "                  epochs = 60,\n",
    "                  batch_size = 256,\n",
    "                  validation_data = ([ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "                                    ratings_test.rating.values - mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./u.user', sep = '|', names = u_cols, encoding = 'latin-1')\n",
    "users = users[['user_id', 'occupation']]\n",
    "\n",
    "occupation = {}\n",
    "def convert_occ(x):\n",
    "    if x in occupation:\n",
    "        return occupation[x]\n",
    "    else:\n",
    "        occupation[x] = len(occupation)\n",
    "        return occupation[x]\n",
    "    \n",
    "users['occupation'] = users['occupation'].apply(convert_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(occupation)\n",
    "train_occ = pd.merge(ratings_train, users, on = 'user_id')['occupation']\n",
    "test_occ = pd.merge(ratings_test, users, on = 'user_id')['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 200\n",
    "mu = ratings_train.rating.mean()\n",
    "M = ratings.user_id.max() + 1\n",
    "N = ratings.movie_id.max() + 1\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = Input(shape = (1, ))\n",
    "item = Input(shape = (1, ))\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer = l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer = l2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer = l2())(user) \n",
    "item_bias = Embedding(N, 1, embeddings_regularizer = l2())(item) \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "P_embedding = Flatten()(P_embedding)\n",
    "Q_embedding = Flatten()(Q_embedding)\n",
    "user_bias = Flatten()(user_bias)\n",
    "item_bias = Flatten()(item_bias)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])\n",
    "\n",
    "occ = Input(shape = (1, ))\n",
    "occ_embedding = Embedding(L, 3, embeddings_regularizer = l2())(occ)\n",
    "occ_layer = Flatten()(occ_embedding)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias, occ_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Dense(2048)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n",
    "model = Model(inputs = [user, item, occ], outputs = R)\n",
    "model.compile(loss = RMSE, optimizer = SGD(), metrics = [RMSE])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(x = [ratings_train.user_id.values, ratings_train.movie_id.values, train_occ.values],\n",
    "                  y = ratings_train.rating.values - mu,\n",
    "                  epochs = 60,\n",
    "                  batch_size = 256,\n",
    "                  validation_data = ([ratings_test.user_id.values, ratings_test.movie_id.values, test_occ.values],\n",
    "                                    ratings_test.rating.values - mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender0(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    return np.array(recommendations)\n",
    "\n",
    "def recommender1(recomm_list):\n",
    "    recommendations = []\n",
    "    for pair in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    return np.array(recommendations)\n",
    "\n",
    "weight = [0.8, 0.2]\n",
    "recomm_list = np.array(ratings_test)\n",
    "predictions0 = recommender0(recomm_list)\n",
    "predictions1 = recommender1(recomm_list)\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(recomm_list[:, 2], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "def recommender1(recomm_list, meighbor_size = 0):\n",
    "    recommendations = np.array([CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
    "predictions0 = recommender0(recomm_list, mf)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
    "\n",
    "predictions1 = recommender1(recomm_list, 37)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions1)\n",
    "\n",
    "weight = [0.8, 0.2]\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "ratings = {'user_id': [1, 2, 4],\n",
    "          'movie_id':[2, 3, 7],\n",
    "          'rating': [4, 3, 1]}\n",
    "ratings = pd.DataFrame(ratings)\n",
    "\n",
    "rating_matrix = ratings.pivot(index = 'user_id', columns = 'movie_id', values = 'rating').fillna(0)\n",
    "full_matrix1 = np.array(rating_matrix)\n",
    "print(full_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(ratings['rating'])\n",
    "row_indices = np.array(ratings['user_id'])\n",
    "col_indices = np.array(ratings['movie_id'])\n",
    "rating_matrix =csr_matrix((data, (row_indices, col_indices)))\n",
    "print(rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix2 = rating_matrix.toarray()\n",
    "print(full_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rating_matrix * 2)\n",
    "print(rating_matrix.T)\n",
    "print(rating_matrix.dot(rating_matrix.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 필요 데이터를 로드한다.\n",
    "use_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./u.user', sep = '|', names = use_cols, encoding = 'latin-1')\n",
    "item_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'unknown',\n",
    "            'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary',\n",
    "             'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "            'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('./u.item', sep='|', names=item_cols, encoding='latin-1')\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./u.data', sep='\\t', names = rating_cols, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "data = np.array(ratings['rating'])\n",
    "row_indices = np.array(ratings['user_id'])\n",
    "col_indices = np.array(ratings['movie_id'])\n",
    "ratings = csr_matrix((data, (row_indices, col_indices)), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = ratings\n",
    "            \n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors ** 2))\n",
    "    \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i + 1, rmse))\n",
    "            if self.verbose:\n",
    "                if(i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f\" % (i +1, rmse))\n",
    "        return training_process\n",
    "    \n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x, y, z = ratings_test.iloc[i]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0\n",
    "        self.test_set = test_set\n",
    "        \n",
    "        return test_set\n",
    "    \n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "    \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "            \n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "            \n",
    "    def test(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "        training_process = []\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i + 1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if(i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f; Test RMSE = %.4f\" % (i +1, rmse1, rmse2))\n",
    "        return training_process\n",
    "    \n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(user_id, item_id)\n",
    "        \n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:, np.newaxis] + self.b_d[np.newaxis, :] + self.P.dot(self.Q.T)\n",
    "    \n",
    "R_temp = ratings.copy()\n",
    "mf = NEW_MF(R_temp, K = 30, alpha = 0.001, beta = 0.02, iterations =100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.indptr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.getrow(0).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in ratings:\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].toarray().ravel()[ratings.indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.getrow(0).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
